{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "# Week 10 Problem Set\n",
    "\n",
    "## Cohort Session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "**CS0.** Do the following tasks before you start with the first cohort session.\n",
    "\n",
    "**Task 1.** Paste the following functions from your previous work:\n",
    "- `get_features_targets()`\n",
    "- `normalize_z()`\n",
    "- `prepare_feature()`\n",
    "- `prepare_target()`\n",
    "- `split_data()`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": true,
    "nbgrader": {
     "grade": false,
     "grade_id": "cs01",
     "locked": false,
     "points": "1",
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "def normalize_z(df):\n",
    "    dfout = (df - df.mean(axis=0)) / df.std(axis=0)\n",
    "    return dfout\n",
    "\n",
    "def get_features_targets(df, feature_names, target_names):\n",
    "    df_feature = df[feature_names]\n",
    "    df_target = df[target_names]\n",
    "    return df_feature, df_target\n",
    "\n",
    "def prepare_feature(df_feature): # creates X matrix\n",
    "    feature = df_feature.to_numpy()\n",
    "    array1 = np.ones((feature.shape[0], 1))\n",
    "#     array1 = np.ones(feature.shape) --> works too\n",
    "    X = np.concatenate((array1, feature), axis=1)\n",
    "    return X\n",
    "\n",
    "def prepare_target(df_target): # creates numpy array for y (target)\n",
    "    return df_target.to_numpy()\n",
    "\n",
    "def split_data(df_feature, df_target, random_state=None, test_size=0.5):\n",
    "    # assuming that index is consistent between features and target\n",
    "    indices = df_target.index\n",
    "    if random_state != None:\n",
    "        np.random.seed(random_state)\n",
    "        \n",
    "    # k is the no. of rows in the test set\n",
    "    num_rows = len(indices)\n",
    "    k = int(test_size * num_rows)\n",
    "    # randomly choose indices for test set\n",
    "    test_indices = np.random.choice(indices, k, replace=False)\n",
    "    \n",
    "    indices = set(indices)\n",
    "    test_indices = set(test_indices)\n",
    "    train_indices = indices - test_indices\n",
    "    \n",
    "    df_feature_train = df_feature.loc[train_indices, :]\n",
    "    df_feature_test = df_feature.loc[test_indices, :]\n",
    "    df_target_train = df_target.loc[train_indices, :]\n",
    "    df_target_test = df_target.loc[test_indices, :]\n",
    "\n",
    "    return df_feature_train, df_feature_test, df_target_train, df_target_test\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "**Task 2.** Load the breast cancer data from `breast_cancer_data.csv` into a Data Frame. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cs02",
     "locked": false,
     "points": "1",
     "solution": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>diagnosis</th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>concave points_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>radius_worst</th>\n",
       "      <th>texture_worst</th>\n",
       "      <th>perimeter_worst</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>concave points_worst</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>fractal_dimension_worst</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>842302</td>\n",
       "      <td>M</td>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.30010</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>...</td>\n",
       "      <td>25.380</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.16220</td>\n",
       "      <td>0.66560</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>842517</td>\n",
       "      <td>M</td>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.08690</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>...</td>\n",
       "      <td>24.990</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.12380</td>\n",
       "      <td>0.18660</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>84300903</td>\n",
       "      <td>M</td>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.19740</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>...</td>\n",
       "      <td>23.570</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.14440</td>\n",
       "      <td>0.42450</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>84348301</td>\n",
       "      <td>M</td>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.24140</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>...</td>\n",
       "      <td>14.910</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.20980</td>\n",
       "      <td>0.86630</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>84358402</td>\n",
       "      <td>M</td>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.19800</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>...</td>\n",
       "      <td>22.540</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.13740</td>\n",
       "      <td>0.20500</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>564</th>\n",
       "      <td>926424</td>\n",
       "      <td>M</td>\n",
       "      <td>21.56</td>\n",
       "      <td>22.39</td>\n",
       "      <td>142.00</td>\n",
       "      <td>1479.0</td>\n",
       "      <td>0.11100</td>\n",
       "      <td>0.11590</td>\n",
       "      <td>0.24390</td>\n",
       "      <td>0.13890</td>\n",
       "      <td>...</td>\n",
       "      <td>25.450</td>\n",
       "      <td>26.40</td>\n",
       "      <td>166.10</td>\n",
       "      <td>2027.0</td>\n",
       "      <td>0.14100</td>\n",
       "      <td>0.21130</td>\n",
       "      <td>0.4107</td>\n",
       "      <td>0.2216</td>\n",
       "      <td>0.2060</td>\n",
       "      <td>0.07115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>565</th>\n",
       "      <td>926682</td>\n",
       "      <td>M</td>\n",
       "      <td>20.13</td>\n",
       "      <td>28.25</td>\n",
       "      <td>131.20</td>\n",
       "      <td>1261.0</td>\n",
       "      <td>0.09780</td>\n",
       "      <td>0.10340</td>\n",
       "      <td>0.14400</td>\n",
       "      <td>0.09791</td>\n",
       "      <td>...</td>\n",
       "      <td>23.690</td>\n",
       "      <td>38.25</td>\n",
       "      <td>155.00</td>\n",
       "      <td>1731.0</td>\n",
       "      <td>0.11660</td>\n",
       "      <td>0.19220</td>\n",
       "      <td>0.3215</td>\n",
       "      <td>0.1628</td>\n",
       "      <td>0.2572</td>\n",
       "      <td>0.06637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>566</th>\n",
       "      <td>926954</td>\n",
       "      <td>M</td>\n",
       "      <td>16.60</td>\n",
       "      <td>28.08</td>\n",
       "      <td>108.30</td>\n",
       "      <td>858.1</td>\n",
       "      <td>0.08455</td>\n",
       "      <td>0.10230</td>\n",
       "      <td>0.09251</td>\n",
       "      <td>0.05302</td>\n",
       "      <td>...</td>\n",
       "      <td>18.980</td>\n",
       "      <td>34.12</td>\n",
       "      <td>126.70</td>\n",
       "      <td>1124.0</td>\n",
       "      <td>0.11390</td>\n",
       "      <td>0.30940</td>\n",
       "      <td>0.3403</td>\n",
       "      <td>0.1418</td>\n",
       "      <td>0.2218</td>\n",
       "      <td>0.07820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>567</th>\n",
       "      <td>927241</td>\n",
       "      <td>M</td>\n",
       "      <td>20.60</td>\n",
       "      <td>29.33</td>\n",
       "      <td>140.10</td>\n",
       "      <td>1265.0</td>\n",
       "      <td>0.11780</td>\n",
       "      <td>0.27700</td>\n",
       "      <td>0.35140</td>\n",
       "      <td>0.15200</td>\n",
       "      <td>...</td>\n",
       "      <td>25.740</td>\n",
       "      <td>39.42</td>\n",
       "      <td>184.60</td>\n",
       "      <td>1821.0</td>\n",
       "      <td>0.16500</td>\n",
       "      <td>0.86810</td>\n",
       "      <td>0.9387</td>\n",
       "      <td>0.2650</td>\n",
       "      <td>0.4087</td>\n",
       "      <td>0.12400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568</th>\n",
       "      <td>92751</td>\n",
       "      <td>B</td>\n",
       "      <td>7.76</td>\n",
       "      <td>24.54</td>\n",
       "      <td>47.92</td>\n",
       "      <td>181.0</td>\n",
       "      <td>0.05263</td>\n",
       "      <td>0.04362</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>9.456</td>\n",
       "      <td>30.37</td>\n",
       "      <td>59.16</td>\n",
       "      <td>268.6</td>\n",
       "      <td>0.08996</td>\n",
       "      <td>0.06444</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.2871</td>\n",
       "      <td>0.07039</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>569 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           id diagnosis  radius_mean  texture_mean  perimeter_mean  area_mean  \\\n",
       "0      842302         M        17.99         10.38          122.80     1001.0   \n",
       "1      842517         M        20.57         17.77          132.90     1326.0   \n",
       "2    84300903         M        19.69         21.25          130.00     1203.0   \n",
       "3    84348301         M        11.42         20.38           77.58      386.1   \n",
       "4    84358402         M        20.29         14.34          135.10     1297.0   \n",
       "..        ...       ...          ...           ...             ...        ...   \n",
       "564    926424         M        21.56         22.39          142.00     1479.0   \n",
       "565    926682         M        20.13         28.25          131.20     1261.0   \n",
       "566    926954         M        16.60         28.08          108.30      858.1   \n",
       "567    927241         M        20.60         29.33          140.10     1265.0   \n",
       "568     92751         B         7.76         24.54           47.92      181.0   \n",
       "\n",
       "     smoothness_mean  compactness_mean  concavity_mean  concave points_mean  \\\n",
       "0            0.11840           0.27760         0.30010              0.14710   \n",
       "1            0.08474           0.07864         0.08690              0.07017   \n",
       "2            0.10960           0.15990         0.19740              0.12790   \n",
       "3            0.14250           0.28390         0.24140              0.10520   \n",
       "4            0.10030           0.13280         0.19800              0.10430   \n",
       "..               ...               ...             ...                  ...   \n",
       "564          0.11100           0.11590         0.24390              0.13890   \n",
       "565          0.09780           0.10340         0.14400              0.09791   \n",
       "566          0.08455           0.10230         0.09251              0.05302   \n",
       "567          0.11780           0.27700         0.35140              0.15200   \n",
       "568          0.05263           0.04362         0.00000              0.00000   \n",
       "\n",
       "     ...  radius_worst  texture_worst  perimeter_worst  area_worst  \\\n",
       "0    ...        25.380          17.33           184.60      2019.0   \n",
       "1    ...        24.990          23.41           158.80      1956.0   \n",
       "2    ...        23.570          25.53           152.50      1709.0   \n",
       "3    ...        14.910          26.50            98.87       567.7   \n",
       "4    ...        22.540          16.67           152.20      1575.0   \n",
       "..   ...           ...            ...              ...         ...   \n",
       "564  ...        25.450          26.40           166.10      2027.0   \n",
       "565  ...        23.690          38.25           155.00      1731.0   \n",
       "566  ...        18.980          34.12           126.70      1124.0   \n",
       "567  ...        25.740          39.42           184.60      1821.0   \n",
       "568  ...         9.456          30.37            59.16       268.6   \n",
       "\n",
       "     smoothness_worst  compactness_worst  concavity_worst  \\\n",
       "0             0.16220            0.66560           0.7119   \n",
       "1             0.12380            0.18660           0.2416   \n",
       "2             0.14440            0.42450           0.4504   \n",
       "3             0.20980            0.86630           0.6869   \n",
       "4             0.13740            0.20500           0.4000   \n",
       "..                ...                ...              ...   \n",
       "564           0.14100            0.21130           0.4107   \n",
       "565           0.11660            0.19220           0.3215   \n",
       "566           0.11390            0.30940           0.3403   \n",
       "567           0.16500            0.86810           0.9387   \n",
       "568           0.08996            0.06444           0.0000   \n",
       "\n",
       "     concave points_worst  symmetry_worst  fractal_dimension_worst  \n",
       "0                  0.2654          0.4601                  0.11890  \n",
       "1                  0.1860          0.2750                  0.08902  \n",
       "2                  0.2430          0.3613                  0.08758  \n",
       "3                  0.2575          0.6638                  0.17300  \n",
       "4                  0.1625          0.2364                  0.07678  \n",
       "..                    ...             ...                      ...  \n",
       "564                0.2216          0.2060                  0.07115  \n",
       "565                0.1628          0.2572                  0.06637  \n",
       "566                0.1418          0.2218                  0.07820  \n",
       "567                0.2650          0.4087                  0.12400  \n",
       "568                0.0000          0.2871                  0.07039  \n",
       "\n",
       "[569 rows x 32 columns]"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read breast_cancer_data.csv\n",
    "df = None \n",
    "df = pd.read_csv(\"breast_cancer_data.csv\")\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "**Task 3.** Do the following tasks.\n",
    "\n",
    "- Read the following columns\n",
    "    - feature: `radius_mean`\n",
    "    - target: `diagnosis`\n",
    "- Normalize the feature column using z normalization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cs03",
     "locked": false,
     "points": "1",
     "solution": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>diagnosis</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>357</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       diagnosis\n",
       "count        569\n",
       "unique         2\n",
       "top            B\n",
       "freq         357"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# extract the feature and the target\n",
    "df_feature, df_target = None, None\n",
    "\n",
    "# normalize the feature\n",
    "df_feature = None\n",
    "# extract the feature and the target\n",
    "df_feature, df_target = get_features_targets(df, [\"radius_mean\"], [\"diagnosis\"])\n",
    "\n",
    "# normalize the feature\n",
    "df_feature = normalize_z(df_feature)\n",
    "\n",
    "###\n",
    "### YOUR CODE HERE\n",
    "###\n",
    "df_target.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "**Task 4.** Write a function `replace_target()` to replace the `diagnosis` column with the following mapping:\n",
    "    - `M`: `1`, this means that malignant cell are indicated as `1` in our new column.\n",
    "    - `B`: `0`, this means that benign cell are indicated as `0` in our new column.\n",
    "    \n",
    "The function should takes in the following:\n",
    "\n",
    "- `df_target`: the target data frame\n",
    "- `target_name`: which is the column name of the target data frame\n",
    "- `map`: which is a dictionary containing the map\n",
    "    \n",
    "It should returns a new data frame with the same column name but with its values changed according to the mapping."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": true,
    "nbgrader": {
     "grade": false,
     "grade_id": "cs04",
     "locked": false,
     "points": "1",
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "def replace_target(df_target, target_name, map_vals):\n",
    "    df_out = df_target.copy()\n",
    "    df_out.loc[:, target_name] = df_target[target_name].apply(lambda val: map_vals[val])\n",
    "    return df_out\n",
    "    \n",
    "\n",
    "# df_target = replace_target(df_target, \"diagnosis\", {\"M\": 1, \"B\":0})\n",
    "# df_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>diagnosis</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>564</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>565</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>566</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>567</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>569 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     diagnosis\n",
       "0            1\n",
       "1            1\n",
       "2            1\n",
       "3            1\n",
       "4            1\n",
       "..         ...\n",
       "564          1\n",
       "565          1\n",
       "566          1\n",
       "567          1\n",
       "568          0\n",
       "\n",
       "[569 rows x 1 columns]"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_target = replace_target(df_target, \"diagnosis\", {'M': 1, 'B': 0})\n",
    "df_target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "**Task 5.** Do the following tasks.\n",
    "- Change feature to Numpy array and append constant 1 column.\n",
    "- Change target to Numpy array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cs05",
     "locked": false,
     "points": "1",
     "solution": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(569, 1)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# change feature data frame to numpy array and append column 1\n",
    "feature = prepare_feature(df_feature)\n",
    "\n",
    "# change target data frame to numpy array\n",
    "target = prepare_target(df_target)\n",
    "\n",
    "target.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "**CS1.** *Logistic function:* Write a function to calculate the hypothesis using a logistic function. Recall that the hypothesis for a logistic regression model is written as:\n",
    "\n",
    "$$\\mathbf{p}(x) = \\frac{1}{1 + e^{-\\mathbf{X}\\mathbf{b}}}$$\n",
    "\n",
    "The shape of the input is as follows:\n",
    "- $\\mathbf{b}$: is a column vector for the parameters\n",
    "- $\\mathbf{X}$: is a matrix where the number of rows are the number of data points and the the number of columns must the same as the number of parameters in $\\mathbf{b}$.\n",
    "\n",
    "Note that you need to ensure that the output is a **column vector**. \n",
    "\n",
    "You can use the following functions:\n",
    "- `np.matmul(array1, array2)`: which is to perform matrix multiplication on the two numpy arrays.\n",
    "- `np.exp()`: which is to calculate the function $e^x$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cs11",
     "locked": false,
     "points": "1",
     "solution": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>diagnosis</th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>concave points_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>radius_worst</th>\n",
       "      <th>texture_worst</th>\n",
       "      <th>perimeter_worst</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>concave points_worst</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>fractal_dimension_worst</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>842302</td>\n",
       "      <td>M</td>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.30010</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>...</td>\n",
       "      <td>25.380</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.16220</td>\n",
       "      <td>0.66560</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>842517</td>\n",
       "      <td>M</td>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.08690</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>...</td>\n",
       "      <td>24.990</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.12380</td>\n",
       "      <td>0.18660</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>84300903</td>\n",
       "      <td>M</td>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.19740</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>...</td>\n",
       "      <td>23.570</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.14440</td>\n",
       "      <td>0.42450</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>84348301</td>\n",
       "      <td>M</td>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.24140</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>...</td>\n",
       "      <td>14.910</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.20980</td>\n",
       "      <td>0.86630</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>84358402</td>\n",
       "      <td>M</td>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.19800</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>...</td>\n",
       "      <td>22.540</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.13740</td>\n",
       "      <td>0.20500</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>564</th>\n",
       "      <td>926424</td>\n",
       "      <td>M</td>\n",
       "      <td>21.56</td>\n",
       "      <td>22.39</td>\n",
       "      <td>142.00</td>\n",
       "      <td>1479.0</td>\n",
       "      <td>0.11100</td>\n",
       "      <td>0.11590</td>\n",
       "      <td>0.24390</td>\n",
       "      <td>0.13890</td>\n",
       "      <td>...</td>\n",
       "      <td>25.450</td>\n",
       "      <td>26.40</td>\n",
       "      <td>166.10</td>\n",
       "      <td>2027.0</td>\n",
       "      <td>0.14100</td>\n",
       "      <td>0.21130</td>\n",
       "      <td>0.4107</td>\n",
       "      <td>0.2216</td>\n",
       "      <td>0.2060</td>\n",
       "      <td>0.07115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>565</th>\n",
       "      <td>926682</td>\n",
       "      <td>M</td>\n",
       "      <td>20.13</td>\n",
       "      <td>28.25</td>\n",
       "      <td>131.20</td>\n",
       "      <td>1261.0</td>\n",
       "      <td>0.09780</td>\n",
       "      <td>0.10340</td>\n",
       "      <td>0.14400</td>\n",
       "      <td>0.09791</td>\n",
       "      <td>...</td>\n",
       "      <td>23.690</td>\n",
       "      <td>38.25</td>\n",
       "      <td>155.00</td>\n",
       "      <td>1731.0</td>\n",
       "      <td>0.11660</td>\n",
       "      <td>0.19220</td>\n",
       "      <td>0.3215</td>\n",
       "      <td>0.1628</td>\n",
       "      <td>0.2572</td>\n",
       "      <td>0.06637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>566</th>\n",
       "      <td>926954</td>\n",
       "      <td>M</td>\n",
       "      <td>16.60</td>\n",
       "      <td>28.08</td>\n",
       "      <td>108.30</td>\n",
       "      <td>858.1</td>\n",
       "      <td>0.08455</td>\n",
       "      <td>0.10230</td>\n",
       "      <td>0.09251</td>\n",
       "      <td>0.05302</td>\n",
       "      <td>...</td>\n",
       "      <td>18.980</td>\n",
       "      <td>34.12</td>\n",
       "      <td>126.70</td>\n",
       "      <td>1124.0</td>\n",
       "      <td>0.11390</td>\n",
       "      <td>0.30940</td>\n",
       "      <td>0.3403</td>\n",
       "      <td>0.1418</td>\n",
       "      <td>0.2218</td>\n",
       "      <td>0.07820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>567</th>\n",
       "      <td>927241</td>\n",
       "      <td>M</td>\n",
       "      <td>20.60</td>\n",
       "      <td>29.33</td>\n",
       "      <td>140.10</td>\n",
       "      <td>1265.0</td>\n",
       "      <td>0.11780</td>\n",
       "      <td>0.27700</td>\n",
       "      <td>0.35140</td>\n",
       "      <td>0.15200</td>\n",
       "      <td>...</td>\n",
       "      <td>25.740</td>\n",
       "      <td>39.42</td>\n",
       "      <td>184.60</td>\n",
       "      <td>1821.0</td>\n",
       "      <td>0.16500</td>\n",
       "      <td>0.86810</td>\n",
       "      <td>0.9387</td>\n",
       "      <td>0.2650</td>\n",
       "      <td>0.4087</td>\n",
       "      <td>0.12400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568</th>\n",
       "      <td>92751</td>\n",
       "      <td>B</td>\n",
       "      <td>7.76</td>\n",
       "      <td>24.54</td>\n",
       "      <td>47.92</td>\n",
       "      <td>181.0</td>\n",
       "      <td>0.05263</td>\n",
       "      <td>0.04362</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>9.456</td>\n",
       "      <td>30.37</td>\n",
       "      <td>59.16</td>\n",
       "      <td>268.6</td>\n",
       "      <td>0.08996</td>\n",
       "      <td>0.06444</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.2871</td>\n",
       "      <td>0.07039</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>569 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           id diagnosis  radius_mean  texture_mean  perimeter_mean  area_mean  \\\n",
       "0      842302         M        17.99         10.38          122.80     1001.0   \n",
       "1      842517         M        20.57         17.77          132.90     1326.0   \n",
       "2    84300903         M        19.69         21.25          130.00     1203.0   \n",
       "3    84348301         M        11.42         20.38           77.58      386.1   \n",
       "4    84358402         M        20.29         14.34          135.10     1297.0   \n",
       "..        ...       ...          ...           ...             ...        ...   \n",
       "564    926424         M        21.56         22.39          142.00     1479.0   \n",
       "565    926682         M        20.13         28.25          131.20     1261.0   \n",
       "566    926954         M        16.60         28.08          108.30      858.1   \n",
       "567    927241         M        20.60         29.33          140.10     1265.0   \n",
       "568     92751         B         7.76         24.54           47.92      181.0   \n",
       "\n",
       "     smoothness_mean  compactness_mean  concavity_mean  concave points_mean  \\\n",
       "0            0.11840           0.27760         0.30010              0.14710   \n",
       "1            0.08474           0.07864         0.08690              0.07017   \n",
       "2            0.10960           0.15990         0.19740              0.12790   \n",
       "3            0.14250           0.28390         0.24140              0.10520   \n",
       "4            0.10030           0.13280         0.19800              0.10430   \n",
       "..               ...               ...             ...                  ...   \n",
       "564          0.11100           0.11590         0.24390              0.13890   \n",
       "565          0.09780           0.10340         0.14400              0.09791   \n",
       "566          0.08455           0.10230         0.09251              0.05302   \n",
       "567          0.11780           0.27700         0.35140              0.15200   \n",
       "568          0.05263           0.04362         0.00000              0.00000   \n",
       "\n",
       "     ...  radius_worst  texture_worst  perimeter_worst  area_worst  \\\n",
       "0    ...        25.380          17.33           184.60      2019.0   \n",
       "1    ...        24.990          23.41           158.80      1956.0   \n",
       "2    ...        23.570          25.53           152.50      1709.0   \n",
       "3    ...        14.910          26.50            98.87       567.7   \n",
       "4    ...        22.540          16.67           152.20      1575.0   \n",
       "..   ...           ...            ...              ...         ...   \n",
       "564  ...        25.450          26.40           166.10      2027.0   \n",
       "565  ...        23.690          38.25           155.00      1731.0   \n",
       "566  ...        18.980          34.12           126.70      1124.0   \n",
       "567  ...        25.740          39.42           184.60      1821.0   \n",
       "568  ...         9.456          30.37            59.16       268.6   \n",
       "\n",
       "     smoothness_worst  compactness_worst  concavity_worst  \\\n",
       "0             0.16220            0.66560           0.7119   \n",
       "1             0.12380            0.18660           0.2416   \n",
       "2             0.14440            0.42450           0.4504   \n",
       "3             0.20980            0.86630           0.6869   \n",
       "4             0.13740            0.20500           0.4000   \n",
       "..                ...                ...              ...   \n",
       "564           0.14100            0.21130           0.4107   \n",
       "565           0.11660            0.19220           0.3215   \n",
       "566           0.11390            0.30940           0.3403   \n",
       "567           0.16500            0.86810           0.9387   \n",
       "568           0.08996            0.06444           0.0000   \n",
       "\n",
       "     concave points_worst  symmetry_worst  fractal_dimension_worst  \n",
       "0                  0.2654          0.4601                  0.11890  \n",
       "1                  0.1860          0.2750                  0.08902  \n",
       "2                  0.2430          0.3613                  0.08758  \n",
       "3                  0.2575          0.6638                  0.17300  \n",
       "4                  0.1625          0.2364                  0.07678  \n",
       "..                    ...             ...                      ...  \n",
       "564                0.2216          0.2060                  0.07115  \n",
       "565                0.1628          0.2572                  0.06637  \n",
       "566                0.1418          0.2218                  0.07820  \n",
       "567                0.2650          0.4087                  0.12400  \n",
       "568                0.0000          0.2871                  0.07039  \n",
       "\n",
       "[569 rows x 32 columns]"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# def log_regression(beta, X):\n",
    "#     z = np.matmul(X,beta)\n",
    "#     return 1 / (1 + np.exp(-z))\n",
    "def log_regression(beta, X):\n",
    "    return 1/(1+np.exp(np.matmul(-X, beta)))\n",
    "\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "cs11",
     "locked": true,
     "points": "1",
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "beta = np.array([0])\n",
    "x = np.array([0])\n",
    "ans = log_regression(beta, x)\n",
    "assert ans == 0.5\n",
    "\n",
    "beta = np.array([2])\n",
    "x = np.array([40])\n",
    "ans = log_regression(beta, x)\n",
    "assert np.isclose(ans, 1.0)\n",
    "\n",
    "beta = np.array([2])\n",
    "x = np.array([-40])\n",
    "ans = log_regression(beta, x)\n",
    "assert np.isclose(ans, 0.0)\n",
    "\n",
    "beta = np.array([[1, 2, 3]])\n",
    "x = np.array([[3, 2, 1]])\n",
    "ans = log_regression(beta.T, x)\n",
    "assert np.isclose(ans.all(), 1.0)\n",
    "\n",
    "beta = np.array([[1, 2, 3]])\n",
    "x = np.array([[3, 2, 1], [3, 2, 1]])\n",
    "ans = log_regression(beta.T, x)\n",
    "assert ans.shape == (2, 1)\n",
    "assert np.isclose(ans.all(), 1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "cs12",
     "locked": true,
     "points": "1",
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "###\n",
    "### AUTOGRADER TEST - DO NOT REMOVE\n",
    "###\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "**CS2.** *Cost Function:* Write a function to calculate the cost function for logistic regression. Recall that the cost function for logistic regression is given by:\n",
    "\n",
    "$$J(\\beta) = -\\frac{1}{m}\\left[\\Sigma_{i=1}^m y^i \\log(p(x^i)) + (1 - y^i) \\log(1 - p(x^i))\\right]$$\n",
    "\n",
    "You can use the following function in your code:\n",
    "- `np.where(condition, then_expression, else_expression)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": true,
    "nbgrader": {
     "grade": false,
     "grade_id": "cs13",
     "locked": false,
     "points": "1",
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "def compute_cost_logreg(beta, X, y):\n",
    "    np.seterr(divide = 'ignore') \n",
    "    p = log_regression(beta,X)\n",
    "    m= X.shape[0]\n",
    "    J = (-1/m)*np.sum(np.where(y==1,np.log(p),np.log(1-p)))\n",
    "    np.seterr(divide = 'warn')\n",
    "    return J\n",
    "\n",
    "# Y=np.array([[1]])\n",
    "# X=np.array([[10,40],[20,50],[30,90]])\n",
    "# beta = np.array([[1,1]]).T\n",
    "# ans = compute_cost_logreg(beta, X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "cs21",
     "locked": true,
     "points": "1",
     "solution": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.0\n",
      "-0.0\n"
     ]
    }
   ],
   "source": [
    "y = np.array([[1]])\n",
    "X = np.array([[10, 40]])\n",
    "beta = np.array([1, 1]).T\n",
    "ans = compute_cost_logreg(beta, X, y)\n",
    "print(ans)\n",
    "assert np.isclose(ans, 0)\n",
    "\n",
    "y = np.array([[0]])\n",
    "X = np.array([[10, 40]])\n",
    "beta = np.array([[-1, -1]]).T\n",
    "ans = compute_cost_logreg(beta, X, y)\n",
    "print(ans)\n",
    "assert np.isclose(ans, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "cs22",
     "locked": true,
     "points": "1",
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "###\n",
    "### AUTOGRADER TEST - DO NOT REMOVE\n",
    "###\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "**CS3.** *Gradient Descent:* Recall that the update functions can be written as a matrix multiplication.\n",
    "\n",
    "$$\\mathbf{b} = \\mathbf{b} - \\alpha\\frac{1}{m}\\mathbf{X}^T(\\mathbf{p} - \\mathbf{y}) $$\n",
    "\n",
    "Write a function called `gradient_descent_logreg()` that takes in five parameters:\n",
    "- `X`: is a 2-D numpy array for the features\n",
    "- `y`: is a vector array for the target\n",
    "- `beta`: is a column vector for the initial guess of the parameters\n",
    "- `alpha`: is the learning rate\n",
    "- `num_iters`: is the number of iteration to perform\n",
    "\n",
    "The function should return two arrays:\n",
    "- `beta`: is coefficient at the end of the iteration\n",
    "- `J_storage`: is the array that stores the cost value at each iteration\n",
    "\n",
    "The solution is similar to Linear Regression gradient descent function with two differences:\n",
    "- you need to use `log_regression()` to calculate the hypothesis\n",
    "- you need to use `compute_cost_logreg()` to calculate the cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": true,
    "nbgrader": {
     "grade": false,
     "grade_id": "cs31",
     "locked": false,
     "points": "1",
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "def gradient_descent_logreg(X, y, beta, alpha, num_iters):\n",
    "    m = X.shape[0]\n",
    "    J_storage = np.zeros(num_iters)\n",
    "    for n in range(num_iters):\n",
    "        p = log_regression(beta, X)\n",
    "        error = p - y\n",
    "        delta = np.matmul(X.T, error)\n",
    "        beta = beta - (alpha / m) * delta\n",
    "        # change the J value from 0 to sum cost (can also use an empty list and append to it)\n",
    "        J_storage[n] = compute_cost_logreg(beta, X, y)\n",
    "    return beta, J_storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "cs31",
     "locked": true,
     "points": "1",
     "solution": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.56630289]\n",
      " [ 1.93763591]]\n"
     ]
    }
   ],
   "source": [
    "iterations = 1500\n",
    "alpha = 0.01\n",
    "beta = np.zeros((2,1))\n",
    "beta, J_storage = gradient_descent_logreg(feature, target, beta, alpha, iterations)\n",
    "\n",
    "print(beta)\n",
    "assert beta.shape == (2, 1)\n",
    "assert np.isclose(beta[0][0], -0.56630)\n",
    "assert np.isclose(beta[1][0], 1.93764)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "cs32",
     "locked": true,
     "points": "1",
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "###\n",
    "### AUTOGRADER TEST - DO NOT REMOVE\n",
    "###\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fb45d4d4390>]"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(J_storage)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "**CS4.** *Predict:* Write two functions `predict()` and `predict_norm()` that calculate the straight line equation given the features and its coefficient.\n",
    "- `predict()`: this function should standardize the feature using z normalization, change it to a Numpy array, and add a column of constant 1s. You should use `prepare_feature()` for this purpose. Lastly, this function should also call `predict_norm()` to get the predicted y values.\n",
    "- `predict_norm()`: this function should calculate the straight line equation after standardization and adding of column for constant 1.\n",
    "\n",
    "You can use the following function in your code:\n",
    "- `np.where()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def predict_norm(X, beta):\n",
    "    p = log_regression(beta, X)\n",
    "    return np.where(p >= 0.5, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def predict(df_feature, beta):\n",
    "    feature_z = normalize_z(df_feature)\n",
    "    X = prepare_feature(feature_z)\n",
    "    return predict_norm(X, beta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "cs41",
     "locked": true,
     "points": "1",
     "solution": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.28998242530755713 0.4537539182423709\n"
     ]
    }
   ],
   "source": [
    "pred = predict(df_feature, beta)\n",
    "print(pred.mean(), pred.std())\n",
    "assert isinstance(pred, np.ndarray)\n",
    "assert np.isclose(pred.mean(), 0.28998)\n",
    "assert np.isclose(pred.std(), 0.45375)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "cs42",
     "locked": true,
     "points": "1",
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "###\n",
    "### AUTOGRADER TEST - DO NOT REMOVE\n",
    "###\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "plt.scatter(df_feature, df_target)\n",
    "plt.scatter(df_feature, pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "**CS5.** *Multiple features and splitting of data set:* \n",
    "\n",
    "Do the following task in the code below:\n",
    "- Read the following column names as the features: `\"radius_mean\", \"texture_mean\", \"perimeter_mean\", \"area_mean\", \"smoothness_mean\", \"compactness_mean\", \"concavity_mean\"`\n",
    "- Read the column `diagnosis` as the target. Change the value from `M` and `B` to `1` and `0` respectively.\n",
    "- Split the data set with 30% test size and `random_state = 100`.\n",
    "- Normalize the training feature data set using `normalize_z()` function.\n",
    "- Convert to numpy array both the target and the features using `prepare_feature()` and `prepare_target()` functions.\n",
    "- Call `gradient_descent()` function to get the parameters using the training data set.\n",
    "- Call `predict()` function on the test data set to get the predicted values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "columns = [\"radius_mean\", \"texture_mean\", \"perimeter_mean\", \"area_mean\", \"smoothness_mean\", \"compactness_mean\", \"concavity_mean\"]\n",
    "\n",
    "# extract the features and the target columns\n",
    "df_features, df_target = get_features_targets(df, columns, [\"diagnosis\"])\n",
    "\n",
    "# replace the target values using from string to integer 0 and 1\n",
    "df_target = replace_target(df_target, \"diagnosis\", {'M':1, 'B':0})\n",
    "\n",
    "# split the data with random_state = 100 and 30% test size\n",
    "df_features_train, df_features_test, df_target_train, df_target_test = split_data(df_features, df_target, random_state=100, test_size=0.3)\n",
    "\n",
    "# normalize the features\n",
    "df_features_train_z = normalize_z(df_features_train)\n",
    "\n",
    "# change the feature columns to numpy array and append column of 1s\n",
    "features = prepare_feature(df_features_train_z)\n",
    "\n",
    "# change the target column to numpy array\n",
    "target = prepare_target(df_target_train)\n",
    "\n",
    "iterations = 1500\n",
    "alpha = 0.01\n",
    "\n",
    "# provide initial guess for theta\n",
    "beta = np.zeros((features.shape[1],1))\n",
    "\n",
    "# call the gradient descent method\n",
    "beta, J_storage = gradient_descent_logreg(features, target, beta, alpha, iterations)\n",
    "\n",
    "###\n",
    "### YOUR CODE HERE\n",
    "###\n",
    "print(beta)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "cs51",
     "locked": true,
     "points": "1",
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert beta.shape == (8, 1)\n",
    "ans = np.array([[-0.6139379 ], \n",
    "                [ 0.82529554],\n",
    "                [ 0.72746485],\n",
    "                [ 0.8236603 ],\n",
    "                [ 0.81647937],\n",
    "                [ 0.5057749 ],\n",
    "                [ 0.44176466],\n",
    "                [ 0.78736842]])\n",
    "assert np.isclose(beta, ans).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "cs52",
     "locked": true,
     "points": "1",
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "###\n",
    "### AUTOGRADER TEST - DO NOT REMOVE\n",
    "###\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "plt.plot(J_storage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# call predict() to get the predicted values\n",
    "pred = predict(df_features_test, beta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "plt.scatter(df_features_test[\"radius_mean\"], df_target_test)\n",
    "plt.scatter(df_features_test[\"radius_mean\"], pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "plt.scatter(df_features_test[\"texture_mean\"], df_target_test)\n",
    "plt.scatter(df_features_test[\"texture_mean\"], pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "plt.scatter(df_features_test[\"perimeter_mean\"], df_target_test)\n",
    "plt.scatter(df_features_test[\"perimeter_mean\"], pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "**CS6.** *Confusion Matrix:* Write a function `confusion_matrix()` that takes in:\n",
    "- `ytrue`: which is the true target values\n",
    "- `ypred`: which is the predicted target values\n",
    "- `labels`: which is a list of the category. In the above case it will be `[1, 0]`. Put the positive case as the first element of the list. \n",
    "\n",
    "The function should return a dictionary containing the matrix with the following format.\n",
    "\n",
    "|                 | predicted positive (1) | predicted negative (0) |\n",
    "|-----------------|--------------------|--------------------|\n",
    "| actual positive (1) | correct positive  (1, 1) | false negative (1, 0)    |\n",
    "| actual negative (0) | false positive (0, 1)   | correct negative (0, 0)   |\n",
    "\n",
    "The keys to the dictionary are the indices: `(0, 0), (0, 1), (1, 0), (1, 1)`.\n",
    "\n",
    "You can use the following function in your code:\n",
    "- `itertools.product()`: this is to create a combination of all the labels. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import itertools\n",
    "def confusion_matrix(ytrue, ypred, labels):\n",
    "    output = {}\n",
    "    generated_key = itertools.product([1,0],repeat = 2)\n",
    "    for k in generated_key:\n",
    "        print(k)\n",
    "        output[k] = 0\n",
    "    for idx in range(len(ytrue)):\n",
    "        true_val=ytrue[idx,0]\n",
    "        pred_val=ypred[idx,0]\n",
    "        output[(true_val, pred_val)] += 1\n",
    "    return output\n",
    "\n",
    "k = itertools.product([1,0], repeat=2)\n",
    "print(list(k))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "cs61",
     "locked": true,
     "points": "1",
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "result = confusion_matrix(df_target_test.values, pred, [1,0])\n",
    "print(result)\n",
    "assert result == {(0, 0): 100, (0, 1): 1, (1, 0): 12, (1, 1): 57}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "**CS7.** *Metrics:* Write a function `calc_accuracy()` that takes in a Confusion Matrix array and output a dictionary with the following keys and values:\n",
    "- `accuracy`: total number of correct predictions / total number of records\n",
    "- `sensitivity`: total correct positive cases / total positive cases\n",
    "- `specificity`: total false positives / total negative cases\n",
    "- `precision`: total  of correct positive cases / total predicted positive cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calc_accuracy(cm):\n",
    "    pospos = cm[(1,1)]\n",
    "    posneg = cm[(1,0)]\n",
    "    negpos = cm[(0,1)]\n",
    "    negneg = cm[(0,0)]\n",
    "    \n",
    "    accuracy = (pospos + negneg) / np.sum(list(cm.values()))\n",
    "    sensitivity = pospos / (pospos + posneg)\n",
    "    specificity = negneg / (negpos + negneg)\n",
    "    precision = pospos / (pospos + negpos)\n",
    "    \n",
    "    result = {'accuracy': accuracy, 'sensitivity': sensitivity,\n",
    "              'specificity': specificity, 'precision': precision}\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "cs71",
     "locked": true,
     "points": "1",
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "ans = calc_accuracy(result)\n",
    "expected = {'accuracy': 0.9235294117647059, 'sensitivity': 0.8260869565217391, 'specificity': 0.9900990099009901, 'precision': 0.9827586206896551}\n",
    "assert np.isclose(ans['accuracy'], expected['accuracy'])\n",
    "assert np.isclose(ans['sensitivity'], expected['sensitivity'])\n",
    "assert np.isclose(ans['specificity'], expected['specificity'])\n",
    "assert np.isclose(ans['precision'], expected['precision'])\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "**CS8.** *Optional:* Redo the above tasks using Scikit Learn libraries. You will need to use the following:\n",
    "- [LogisticRegression](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html)\n",
    "- [train_test_split](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html)\n",
    "- [confusion_matrix](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.confusion_matrix.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "columns = [\"radius_mean\", \"texture_mean\", \"perimeter_mean\", \"area_mean\", \"smoothness_mean\", \"compactness_mean\", \"concavity_mean\"]\n",
    "# get the features and the columns\n",
    "df_features = None\n",
    "\n",
    "# replace target values with 0 and 1\n",
    "df_target = None\n",
    "\n",
    "###\n",
    "### YOUR CODE HERE\n",
    "###\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# split data set using random_state = 100 and 30% test size\n",
    "df_features_train, df_features_test, df_target_train, df_target_test = None, None, None, None\n",
    "\n",
    "# change feature to numpy array and append column of 1s\n",
    "feature = None\n",
    "\n",
    "# change target to numpy array\n",
    "target = None\n",
    "\n",
    "###\n",
    "### YOUR CODE HERE\n",
    "###\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create LogisticRegression object instance, use newton-cg solver\n",
    "model = None\n",
    "\n",
    "# build model\n",
    "pass\n",
    "\n",
    "# get predicted value\n",
    "pred = None\n",
    "\n",
    "###\n",
    "### YOUR CODE HERE\n",
    "###\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# calculate confusion matrix\n",
    "cm = None\n",
    "\n",
    "###\n",
    "### YOUR CODE HERE\n",
    "###\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cs81",
     "locked": true,
     "points": "1",
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "expected = np.array([[58,  11], [6, 96]])\n",
    "assert (cm == expected).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "plt.scatter(df_features_test[\"radius_mean\"], df_target_test)\n",
    "plt.scatter(df_features_test[\"radius_mean\"], pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "plt.scatter(df_features_test[\"texture_mean\"], df_target_test)\n",
    "plt.scatter(df_features_test[\"texture_mean\"], pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "plt.scatter(df_features_test[\"perimeter_mean\"], df_target_test)\n",
    "plt.scatter(df_features_test[\"perimeter_mean\"], pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 [3.7]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
